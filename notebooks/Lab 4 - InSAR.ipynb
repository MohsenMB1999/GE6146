{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4 - InSAR\n",
    "As we have seen from the videos and lectures, SAR (Synthetic Aperature RADAR) is a widely-used remote sensing technique for measuring a range of surface properties. This class is about geodetic-type remote sensing measurements, so we will focus on InSAR, or Interferometric SAR. In this lab you will gain some experience accessing, modeling, and interpreting InSAR data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some imports\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Modeling an earthquake using Visible Earthquakes \n",
    "In this part of the lab you will use a website called __[Visible Earthquakes](https://earthquakes.aranzgeo.com/)__ to model a normal-faulting earthquake that happened in Turkey in 1995, as well as a second earthquake of your choice. Navigate to the webpage and go through the __[tutorial](https://earthquakes.aranzgeo.com/start)__ on how to use the site. Then navigate back to the home page and select the **Dinar Earthquake**. You can use both the wrapped and unwrapped versions of the data to help you determine the best parameters for the event. Once you have your best-fitting model, put the results in the cell below. Make sure to match the parameter values to the order given in the comment. After completing the assignment for the Dinar earthquake, pick another earthquake of your choice and follow the same procedure. Be sure to mark which earthquake you did and what parameters you chose!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_dinar = np.array([strike, dip, rake, length,slip,depth,center,magnitude])\n",
    "param_dinar = None # add the parameters of your best-fit model\n",
    "\n",
    "# Second earthquake\n",
    "eq_name = None  # add the name of the second earthquake you did. \n",
    "param_second = None # add the parameters of your best-fit model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Accessing and analyzing InSAR data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## InSAR Data sources\n",
    "There are several places and ways to access InSAR data. Some data is available directly as InSAR: SAR products that have already been pre-processed and interfered to produce an interferogram, two SAR acquisitions that have been differenced. \n",
    "\n",
    "###__[1. Alaska Satellite Facility](https://asf.alaska.edu/)__\n",
    "The __[ASF search page](https://search.asf.alaska.edu/#/)__ interactive webpage allows you to select a region or specify a bounding box, select which products you are interested in, download individual products, or perform a bulk download using a Python script. This site is most useful if you will processing SAR data into InSAR products, but it also contains the ARIA interferograms that we will use in this lesson. This site has SAR/InSAR data available from several different missions, including RADARSAT-1, Sentinel-1, JPL's UAVSAR, ALOS-PALSAR, and some ERS data.\n",
    "<img src=\"https://raw.githubusercontent.com/jlmaurer/GE6146/master/notebooks/images/Vertex_homescreen.png\" alt=\"Vertex home page\" width=\"700\">\n",
    "\n",
    "### __[2. ARIA](https://aria.jpl.nasa.gov/)__\n",
    "The ARIA project is \"a collaboration between JPL and Caltech to exploit radar and optical remote sensing, GPS, and seismic observations for hazard science and response.\" They will eventually provide automatic and real-time processing of SAR, InSAR, and GNSS data to aid in rapid response to all kinds of earth hazards, including earthquakes, volcanoes, large landslides, flooding, storms, etc. Accessing InSAR data using ARIA can be done through ASF or through the __[ARIA-tools](https://github.com/aria-tools/ARIA-tools)__ API, which is what we will use in this lab. \n",
    "<img src=\"https://raw.githubusercontent.com/jlmaurer/GE6146/master/notebooks/images/ARIA_homepage.png\" alt=\"ARIA project home page\" width=\"700\">\n",
    "\n",
    "### __[3. UAVSAR](https://uavsar.jpl.nasa.gov/)__\n",
    "JPL's airborne SAR sensor is called \"UAVSAR\" for \"Uninhabited Aeriel Vehicle SAR\" (although the vehicle almost always actually inhabited!). This mission collects airborne SAR data and makes interferograms available on the __[project website](https://uavsar.jpl.nasa.gov/)__. On their website you can search for and download data for the specific areas where it has been acquired; unlike satellite-based sensors, UAVSAR is on-demand, so it is not acquired everywhere nor all the time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Workflow Considerations\n",
    "How you process the data to get a result that can be used for geodetic purposes depends on what data you access; i.e.,  Single-Look complex (SLC) products in radar coordinates versus geocoded interferograms. The process you will want to use will depend on several factors, including: \n",
    "1. What data is available, and in what format. This includes:  \n",
    "   - Does the data you want exist?\n",
    "   - Has it been processed already, and to what level? \n",
    "   - Do you need a single pair (interferogram), or do you need to look at time-series?\n",
    "   - Is the data publically available or will you need to access it through other means (e.g. writing a grant)\n",
    "   - Does the data exist at the necessary resolution, temporal sampling, etc. for your application?\n",
    "2. What processing algorithms you have access to use or know how to use?  \n",
    "   - Some algorithms are open-source and cross-platform, others must be paid for or only work on one OS\n",
    "   - Some algoirthms are simple and do a few things, others are complex and do many things\n",
    "   - How precise do your measurements need to be? If your signal is large, you can use simpler processing techniques and still get a useful signal, but if your signal is small you will need to use the best possible methods to perform your analysis. \n",
    "3. Do you need time-series analysis or single event pairs? \n",
    "4. What computational capabilities (computers, servers, memory, disk space) do you need and do you have access to it?  \n",
    "   - SAR/InSAR scenes can be large, and processing several can be very computational intensive. \n",
    "   - You will need **large memory, processing power, and storage space** capabilities\n",
    "   - In most cases, access to specialized equipment like many processors or GPUs can significantly aid computational capabilities.  \n",
    "5. There are many software tools and cutting-edge advanced processing techniques that we will not delve into in this class, but may be useful to you for futher research. Note that some of these are research-grade codes or otherwise not well developed, so learning to use them could take some significant time and effort. Some of these are:  \n",
    "   - __[The Sentinel-1 toolbox, or SNAP](https://sentinel.esa.int/web/sentinel/toolboxes/sentinel-1)__\n",
    "   - __[ISCE](https://github.com/isce-framework)__ is a general-purpose processing software for InSAR developed by folks at JPL and elsewhere, written in Python\n",
    "   - __[GMTSAR](https://topex.ucsd.edu/gmtsar/)__ is a general InSAR processing tool developed by folks at Scripps Institute of Oceanography, writting in the GMT language\n",
    "   - __[STAMPS](https://github.com/dbekaert/StaMPS)__ for advanced time-series analysis\n",
    "   - Various tools for atmospheric corrections: __[TRAIN](https://github.com/dbekaert/TRAIN)__, __[GACOS]()__, __[RAiDER](https://github.com/dbekaert/RAiDER)__ (which I have worked on), and __[PyAPS](http://earthdef.caltech.edu/projects/pyaps/wiki/Main)__.\n",
    "   - __[MintPy](https://github.com/insarlab/MintPy)__ for InSAR time-series analysis (__[Mintpy tutorial)](https://github.com/insarlab/MintPy-tutorial)__\n",
    "   - __[PyRate](https://github.com/GeoscienceAustralia/PyRate)__ is a Python tool for InSAR time-series analysis\n",
    "   - __[GIAnT](http://earthdef.caltech.edu/projects/giant/wiki)__ is yet another InSAR time-series package written in Python\n",
    "   \n",
    "__[UNAVCO](https://www.unavco.org/)__ has a number of __[educational resources](https://www.unavco.org/education/education.html)__ available for learning to use the general-purpose InSAR processors, including a __[short courses](https://www.unavco.org/education/professional-development/short-courses/short-courses.html)__, one of which will be __[taught this year](https://www.unavco.org/education/professional-development/short-courses/2020/insar-theory-processing/insar-theory-processing.html)__, and __[past courses](https://www.unavco.org/education/professional-development/short-courses/course-materials/course-materials.html)__ as well. \n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/jlmaurer/GE6146/master/notebooks/images/UNAVCO_homescreen.png\" alt=\"UNAVCO home page\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lab we will use a __[shared Google Drive folder](https://drive.google.com/drive/folders/1hm3FD0vQXbdvaR2wMXg3GC9AYgYTYBj6?usp=sharing)__ so that you do not need to separately download data. I have already download the data required for this lab to the data/ folder inside the linked shared folder, so you can directly access that. Python programs required for this lab are also in the shared folder so that they are accessible to us while we go through the lab. \n",
    "\n",
    "**Each of you have a read/write/edit Google folder inside the shared folder, where you can save intermediate products or results, or even save a copy of this notebook. If you need to save or write data during this lab, use this folder!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "kxYkfzTorfZf",
    "outputId": "4b9f8069-a67b-4f75-bb24-d718d8b55587"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e5b0420cd036>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/gdrive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "tVlW6eitrkQD",
    "outputId": "8471a129-ddc8-4700-fd88-29349b23fc33"
   },
   "outputs": [],
   "source": [
    "# Change to the ARIAtools directory on the shared Google Drive\n",
    "%cd /gdrive/My\\ Drive/GE6371/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some libraries to be used later\n",
    "import os\n",
    "import numpy as np\n",
    "from osgeo import gdal, ogr\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter, FormatStrFormatter, StrMethodFormatter\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "!pip install ARIAtools/ARIA-tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. InSAR processing with ARIA products\n",
    "**Authors**: Brett A. Buzzanga, David Bekaert, Simran Sangha - Jet Propulsion Laboratory, Jeremy Maurer - Missouri S&T\n",
    "\n",
    "In this notebook we will learn how to use the ARIA family of command line tools to access Sentinel 1 ARIA Geocoded UNWrapped interferogram (**GUNW**) products.  A detailed overview of the ARIA GUNW product with respect to processing, formatting, sampling, and data layers can be found on the __[ARIA website](https://aria.jpl.nasa.gov/node/97)__. This notebook has been modified from the __[ARIA-tool-docs](https://github.com/aria-tools/ARIA-tools-docs)__ repository, which holds the original notebooks. The ARIA-tools code can be found at the __[Github repository](https://github.com/aria-tools/ARIA-tools)__. \n",
    "\n",
    "### Downloading GUNW products using ariaDownload.py\n",
    "The **`ariaDownload.py`** program wraps around the NASA's ASF DAAC API and __[Bulk Download Service](https://bulk-download.asf.alaska.edu/help)__. The ASF Bulk Download Service handles most of the heavy lifting of the data-download and will conveniently skip previously downloaded files, and re-download partially downloaded files.  \n",
    "In this notebook, we will demonstrate **`ariaDownload.py`** functionality along track 4, which intersects the U.S. East Coast in southeastern Virginia.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>Potential download failure:</b>\n",
    "GUNW products are hosted at the NASA ASF DAAC. Downloading them requires a NASA Earthdata URS user login and requires users to add “ARIA Product Search” to their URS approved applications\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "<b>Download</b>:     \n",
    "    \n",
    "- The ***jupyter notebook* does not allow for interactive entering of your user-name and password, use the *jupyter terminal* instead** with the same command for interactive use.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running **`ariaDownload.py`** with no options, or with **`-h`**, will show the parameters options as well as some examples. At minimum, users need to specify a spatial constraint either as a track number or bounding box (can be a shapefile).\n",
    "\n",
    "Let us explore what some of the other options are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 731
    },
    "colab_type": "code",
    "id": "H26ghjAcrtqm",
    "outputId": "6a9ad75d-6356-416f-d262-7aaeb17a76a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: ariaDownload.py [-h] [-o OUTPUT] [-t TRACK] [-b BBOX] [-w WD]\n",
      "                       [-s START] [-e END] [-l DAYSLT] [-m DAYSGT] [-i IFG]\n",
      "                       [-d FLIGHTDIR] [-v]\n",
      "\n",
      "Command line interface to download GUNW products from the ASF DAAC. GUNW products are hosted at the NASA ASF DAAC.\n",
      "Downloading them requires a NASA Earthdata URS user login and requires users to add \"ARIA Product Search\" to their URS approved applications.\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  -o OUTPUT, --output OUTPUT\n",
      "                        Output type, default is \"Download\". \"Download\",\n",
      "                        \"Count\", \"Url\" and \"Kmz\" are currently supported. Use\n",
      "                        \"Url\" for ingestion to aria*.py\n",
      "  -t TRACK, --track TRACK\n",
      "                        track to download; single number (including leading\n",
      "                        zeros) or comma separated\n",
      "  -b BBOX, --bbox BBOX  Lat/Lon Bounding SNWE, or GDAL-readable file\n",
      "                        containing POLYGON geometry.\n",
      "  -w WD, --workdir WD   Specify directory to deposit all outputs. Default is\n",
      "                        \"products\" in local directory where script is\n",
      "                        launched.\n",
      "  -s START, --start START\n",
      "                        Start date as YYYYMMDD; If none provided, starts at\n",
      "                        beginning of Sentinel record (2014).\n",
      "  -e END, --end END     End date as YYYYMMDD. If none provided, ends today.\n",
      "  -l DAYSLT, --daysless DAYSLT\n",
      "                        Take pairs with a temporal baseline -- days less than\n",
      "                        this value.\n",
      "  -m DAYSGT, --daysmore DAYSGT\n",
      "                        Take pairs with a temporal baseline -- days greater\n",
      "                        than this value. Example, annual pairs:\n",
      "                        ariaDownload.py -t 004 --daysmore 364.\n",
      "  -i IFG, --ifg IFG     Retrieve one interferogram by its start/end date,\n",
      "                        specified as YYYYMMDD_YYYYMMDD (order independent)\n",
      "  -d FLIGHTDIR, --direction FLIGHTDIR\n",
      "                        Flight direction, options: ascending, a, descending, d\n",
      "  -v, --verbose         Print products to be downloaded to stdout\n",
      "\n",
      "Examples of use:\n",
      "\t ariaDownload.py --track 004 --output count\n",
      "\t ariaDownload.py --bbox \"36.75 37.225 -76.655 -75.928\"\n",
      "\t ariaDownload.py -t 004,077 --start 20190101 -o count\n"
     ]
    }
   ],
   "source": [
    "# Display the help message for ariaDownload.py\n",
    "!ariaDownload.py -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Count the number of products**  \n",
    "To get a count of the number of products, without downloading data, provide the **`--output`** option with the **`count`** argument. To get information on the exact product filenames also include the verbose option **`-v`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of acquisitions for track 4\n",
    "!ariaDownload.py --track 4 --output count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate list of virtual products from ASF S3 bucket (BETA)**  \n",
    "To generate a textfile containing a list of product URLs from the ASF S3 bucket, without downloading data, provide the **`--output`** option with the **`url`** argument. To get information on the exact product filenames also include the verbose option **`-v`**. Extracting layers virtually by leveraging this list of URLs is currently only supported by systems with the following packages: Linux kernel >=4.3 and libnetcdf >=4.5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a file to your writeable folder in Google drive using the --output url\n",
    "!ariaDownload.py --track 4 --output url -w <your_writeable_folder>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate KMZ of the products**  \n",
    "To generate a Google Earth kmz, without downloading data, provide the **`--output`** option with the **`kmz`** argument. In case you also want to get information on the exact product filenames you can enbale the verbose option by adding **`-v`**. The result is shown in **Fig. 1**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure to specify the correct folder to write to using the -w option\n",
    "!ariaDownload.py --track 4 --output kmz -w <your_writeable_folder>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Download the data**  \n",
    "To download the products, simply omit the **`--output`** option or specify it with the **`download`** argument. Examples for downloading all data on track 4 include:\n",
    "\n",
    "`ariaDownload.py -t 004`\n",
    "\n",
    "`ariaDownload.py -t 004 -o download`\n",
    "\n",
    "\n",
    "By default, the products will be downloaded into the *./products* folder. You can specify a different location using the **`-w`** option, such as:\n",
    "\n",
    "`ariaDownload.py -t 004 -w /insarHome`\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>Potential download failure:</b>\n",
    "GUNW products are hosted at the NASA ASF DAAC. Downloading them requires a NASA Earthdata URS user login and requires users to add “ARIA Product Search” to their URS approved applications\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "<b>Download</b>: \n",
    "- You will not need to actually download any data for this lab; I have already downloaded the data and made it available in the data/ folder in the shared Google drive. However, you will need to download data to your own location if you use InSAR for your final project. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Spatial-temporal subsetting**  \n",
    "The **`ariaDownload.py`** program has a number of options availble for subsetting the search of products in the spatial and temporal domain, including **bounding box**, **start/end date**, **aquisition geometry**, **temporal baseline**, or **interferogram** options. Below, using the count option for brevity, we demonstrate each of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Specify a bounding box**  \n",
    "Bounding box can either be specified as **SNWE** coordinates (a string with quotation) or by providing a **shapefile** (GeoJSON or ESRI shapefiles) to the **`--bbox`** option. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An example for track 4 over eastern US\n",
    "!ariaDownload.py --track 4 --bbox \"36.75 37.225 -76.655 -75.928\" -o count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Subsetting by start/end date**  \n",
    "Subsetting in time can be done by specifying a range within which products need to fall. This is controlled using the **`--start YYYYMMDD` ** and **`--end YYYYMMDD`** options. By default the complete observational record is considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ariaDownload.py --track 4 --bbox \"36.75 37.225 -76.655 -75.928\" -o count -s 20190101  --end 20190401 --verbose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Specifying by a specific interferogram** \n",
    "To find a specific interferogram combination one can use the **`--ifg YYYYMMDD_YYYYMMDD`** option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ariaDownload.py -b \"36.75 37.225 -76.655 -75.928\"  -o count --ifg \"20161018_20160702\" -v "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An example: Kilauea volcano, Hawaii\n",
    "In this lab we will look at some data covering the Big Island of Hawaii, during early 2018 when the Kilauea volcano was erupting. (You can read more about the eruption __[here](https://www.usgs.gov/news/k-lauea-volcano-erupts)__. We will use ARIA data from the time period during the eruption to analyze deformation during the event. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "FIDj5GR8r_0w",
    "outputId": "8dac049c-4b0a-43b5-f77c-c5ce839992df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python: can't open file 'ARIA-tools/tools/bin/ariaDownload.py': [Errno 2] No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "# Check how many acquisitions are available from January to July 2018 over Hawaii, when Kilauea volcano was erupting on the Big Island\n",
    "!ariaDownload.py --track 124 -b '18.8 20.3 -156.2 -154.6' -d ascending -s 20180101 -e 20180701  --output count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YHcrvzm8vFiB"
   },
   "outputs": [],
   "source": [
    "# I've already downloaded the data to the Google Drive, look at it by running this cell\n",
    "!ls data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Plotting the data with ariaPlot.py\n",
    "The **ariaPlot.py** program allows for easy generation of qualitative and spatiotemporal coverage plots of products over a user-defined area of interest. Running **ariaPlot.py** with the **-h** option, will show the parameters options. \n",
    "\n",
    "Let us explore these options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python: can't open file 'ARIA-tools/tools/bin/ariaPlot.py': [Errno 2] No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "# ariaPlot.py help menu\n",
    "!ariaPlot.py -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Specifying which products to use**  \n",
    "At minimum, users need to specify the GUNW files they want to extract information from. This is controlled using the **`-f`** option. Multiple products can be specified by providing them as a comma separated string (e.g., **`-f`**` 'products/S1-GUNW-D-R-042-tops-20150605_20150512-140722-39616N_37642N-PP-e396-v2_0_0.nc,products/S1-GUNW-D-R-042-tops-20150629_20150512-140723-39615N_37641N-PP-0e95-v2_0_0.nc'`), or using a wildcard (e.g., **`-f`**` 'products/S1*.nc'`).\n",
    "\n",
    "**Cropping and spatial subsetting (-b and -croptounion options)**  \n",
    "The **`ariaPlot.py`** program will automatically handle cropping and stitching of GUNW products when needed. By default, the program will crop all interferograms to bounds determined by the common intersection (of all interferograms) and the user-defined bounding box option. All layers are cropped and/or stitched using GDAL (see the methods section for details on the implemented approach for each layer). Below we discuss which options are available for specifying an area-of-interest.\n",
    "\n",
    "GUNW products are grouped in clusters that belong to the same interferometric pair. By default, the spatial **intersection** of the interferometic pairs is used to define the region of interest. This can be overriden to be the union of all interferograms (regardless of alignment) by passing the **`--croptounion`** argument. A schematic example is shown in **Fig 1** for both scenario's.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>Warning:</b> Users in general should avoid mixing products of adjacent satellite tracks (i.e., products made on the same contiguous pass are ok). Note that along the equator, the track number (ascending data on the ascending note) gets incremented while the data itself is still continuous.\n",
    "</div>\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/jlmaurer/GE6146/master/notebooks/images/spatial_config_new.png\" alt=\"spatial_configuration\" width=\"700\">\n",
    "<blockquote> <center><b> Fig. 1 </b> Schematic of the spatiotemporal configuration for three interferograms. The left panel shows the intersection of the interferograms, which is the default behavior. The right panel shows the union of the interferograms, achieved by passing <b><code>--croptounion</code></b> . The blue dashed line demonstrates the behavior if the user had specified a bounding box (<b><code>-b</code></b>). Note that interferograms which do not cover the bounding box completely with the <b><code>--croptounion</code></b> or the <b><code>-b</code></b> option will be patched with no-data values.</center></blockquote>\n",
    "\n",
    "Users can analyze the interferogram quality over their study area using the interferogram baseline and average coherence information. **`ariaPlot.py`** allows users to visualize this information directly from the GUNW products. Three main options are available that can assist users for a qualitative assessment. The **`--plotbperpcoh`** option generates a perpendicular baseline plot over time, color-coded with average coherence. An alternative representation is provided by the **`--plotcoh`** option, which shows just the average interferogram coherence over time. Lastly, the **`--makeavgoh`** option can be leveraged for making a 2D product of average coherence in time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating plots in ARIA-tools\n",
    "The following commented-out command would generate the plots described in the last section. I have already generated the plots and you can see them in the /plots folder. Open the plots and look at them on your local computer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a \"figues\" directory inside your writeable directory and replace <your_user_name> \n",
    "# with your writeable directory name, for example: jlmd9g/figures. \n",
    "#!ariaPlot.py -f \"data/*.nc\"   --plotcoh --plotbperpcoh --makeavgoh -w <your_user_name>/figures>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: figures: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "# Look at the files in your figures directory. You can open these on directly from your Google Drive \n",
    "# (not in this notebook)\n",
    "!ls plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can use this function as is (do not need to modify it)\n",
    "def plot_layer(path_layer, lay_type=None, cmap=None, **kwargs):\n",
    "    \"\"\" \n",
    "        path_layers is a string to the GDAL compatible dataset to be plotted\n",
    "    \"\"\"\n",
    "    \n",
    "    if not lay_type: \n",
    "        lay_type = os.path.dirname(path_layer)\n",
    "    title = [os.path.basename(lay_type)]\n",
    "    \n",
    "    ## get the lon lat bounds\n",
    "    ds       = gdal.Open(path_layer, gdal.GA_ReadOnly)\n",
    "    trans    = ds.GetGeoTransform()\n",
    "    extent   = [trans[0], trans[0] + ds.RasterXSize * trans[1], trans[3] + ds.RasterYSize*trans[5], trans[3]]\n",
    "    \n",
    "    ## loading the data\n",
    "    n_bands  = ds.RasterCount\n",
    "    lst_arrs = []\n",
    "    \n",
    "    for band in range(n_bands):\n",
    "        raster = ds.GetRasterBand(band+1)\n",
    "        arr    = raster.ReadAsArray()\n",
    "        try:\n",
    "            NoData = raster.GetNoDataValue()\n",
    "            arr = np.ma.masked_where((arr>1e20) |(arr==NoData),arr )\n",
    "        except:\n",
    "            print('Could not find a no-data value...')\n",
    "            arr = np.ma.masked_where(arr>1e20,arr)\n",
    "        \n",
    "        lst_arrs.append(arr)\n",
    "\n",
    "    ds = None\n",
    "    if n_bands < 4:\n",
    "        nrows = 1; ncols = n_bands\n",
    "    else:\n",
    "        raise Exception('Number of bands currently unsupported')\n",
    "        \n",
    "    \n",
    "    ## initializing a figure\n",
    "    fig, axes = plt.subplots(figsize=(12,9), ncols=ncols, nrows=nrows, sharex='col', sharey='row')\n",
    "    axes = axes if isinstance(axes, np.ndarray) else np.array(axes)\n",
    "    axe  = axes.ravel() \n",
    "    cmap = plt.cm.Greys_r\n",
    "    cmap.set_under('black')\n",
    "    \n",
    "    ## definging the plotting options for differnt layer types\n",
    "    # Amplitude:\n",
    "    if lay_type.endswith('amplitude'): \n",
    "        # will fix the maximum amplitude bound\n",
    "        vmin=None\n",
    "        vmax = 2000 \n",
    "    # Coherence:\n",
    "    elif lay_type.endswith('coherence'): \n",
    "        # has fixed range between 0-1\n",
    "        vmin=0\n",
    "        vmax = 1\n",
    "    # Incidence angle:\n",
    "    elif lay_type.endswith('incidenceAngle'): \n",
    "        vmin=None\n",
    "        vmax=None\n",
    "    # water\n",
    "    elif lay_type.startswith('water'):\n",
    "        # no bounds needed will be a 0/1 mask\n",
    "        vmin=None\n",
    "        vmax=None\n",
    "    # deformation or unwrapped phase\n",
    "    elif lay_type.startswith('defo'): \n",
    "        # let the data drive the bounds\n",
    "        vmin=None\n",
    "        vmax=None\n",
    "        # change colormap to a warm type\n",
    "        cmap=plt.cm.coolwarm\n",
    "    elif lay_type.startswith('terr') or lay_type.startswith('topo'): \n",
    "        # let the data drive the bounds\n",
    "        vmin=None\n",
    "        vmax=None\n",
    "        # change colormap to a warm type\n",
    "        cmap=plt.cm.terrain\n",
    "    elif lay_type == 'ENU':\n",
    "        vmin=None\n",
    "        vmax=None\n",
    "        title = ['East', 'North', 'Up']\n",
    "        fig.subplots_adjust(wspace=0.5)\n",
    "\n",
    "    else:\n",
    "        # let the data drive the bounds\n",
    "        vmin=None\n",
    "        vmax=None\n",
    "        # change colormap to a warm type\n",
    "        cmap=plt.cm.coolwarm\n",
    "        \n",
    "    # plotting the data    \n",
    "    for i, ax in enumerate(axe):\n",
    "        im   = ax.imshow(lst_arrs[i], cmap=cmap, vmin=vmin, vmax=vmax, extent=extent)\n",
    "        divider = make_axes_locatable(ax)\n",
    "        cax     = divider.append_axes('right', size='5%', pad=0.25)\n",
    "        if lay_type == 'ENU':\n",
    "            fig.colorbar(im, cax=cax, format=FuncFormatter(lambda x, y: '{:.3f}'.format(x)))\n",
    "        else:\n",
    "            fig.colorbar(im, cax=cax)\n",
    "\n",
    "        ax.set_title(title[i], fontsize=15)\n",
    "        ax.grid(False)\n",
    "\n",
    "    axe[0].set_ylabel('latitude', labelpad=15, fontsize=15)\n",
    "    axe[int(np.floor(n_bands/2))].set_xlabel('longitude', labelpad=15, fontsize=15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preparing ARIA standard GUNW products layers for time-series analysis using ariaTSsetup.py\n",
    "\n",
    "**Author**: Simran Sangha, David Bekaert - Jet Propulsion Laboratory\n",
    "\n",
    "This notebook provides an overview of the functionality included in the **ariaTSsetup.py** program. Specifically, we give examples on how to extract data and meta-data layers from ARIA Geocoded UNWrapped interferogram (GUNW) products over a user defined area of interest and prepare the data into a stack for time-series ingestion.\n",
    "\n",
    "In this notebook, we will demonstrate how to:\n",
    "- Extract data layers (unwrapped phase, coherence) and imaging geometry layers (azimuth angle, incidence angle, look angle) necessary for building time-series\n",
    "- Prepare the extracted data into a stack for time-series ingestion\n",
    "\n",
    "    \n",
    "<div class=\"alert alert-warning\">\n",
    "Both the initial setup (<b>Prep A</b> section) and download of the data (<b>Prep B</b> section) should be run at the start of the notebook. The overview sections do not need to be run in order. In the application section the ariaTSsetup commandline call at the top must be run first, but the rest of the section does not need to be run in order.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "<b>Potential Errors:</b> \n",
    "    \n",
    "- GDAL uses \"HDF5\" driver instead of \"netCDF/Network Common Data Format\" on GUNW products. Verify GDAL version >= 3.\n",
    "- ARIA-tools needs to be installed to run this notebook\n",
    "</div>\n",
    "\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    <b>Terminology:</b>\n",
    "    \n",
    "- *Acquisition*: An image acquired by the satellite for a given date and time.\n",
    "- *Interferogram*: An unwrapped image containing the surface displacement accumulated between two acquisitions.\n",
    "- *Frame*: Outline of a product ground footprint.\n",
    "- *Along-track*: The direction along satellite flight path. \n",
    "    </div>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the help menu\n",
    "!ariaTSsetup.py -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following command would be used to generate the products that will go into the time-series analysis. I've already processed the data and made it available in my folder, /jlmd9g. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the interferograms for time-series analysis\n",
    "# Make sure to specify your username directory!\n",
    "# !ariaTSsetup.py -f 'data/*.nc' -b '18.8 20.3 -156.2 -154.6' -d Download --mask Download -w <your_user_name>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls jlmd9g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is a water mask generated that will be used to ignore pixels covering the ocean\n",
    "plot_layer('jlmd9g/mask/watermask.msk',lay_type='water')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the downloaded DEM\n",
    "plot_layer('jlmd9g/DEM/SRTM_3arcsec.dem',lay_type='topo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the coherence of one of the acquisitions\n",
    "plot_layer('jlmd9g/coherence/20180114_20180108',lay_type='coherence')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. InSAR time-series analysis\n",
    "For looking at earthquakes and other large deformation, often one or two interferograms will be sufficient to see the deformation. For smaller or long-term processes, InSAR time-series must be used. This introduces some more complexity into the processing because of the need to co-register interferograms and account for various noise sources. In the next example, you will use a simple InSAR time-series generator to look at deformation during the 2018 Kilauea volcano eruption on the Big Island of Hawaii. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 2018 Kilauea eruption resulted in uplift at the volcano because of extrusion of lava and injection of magma into the shallow subsurface, but the summit of the mountain deflated because magma moved from under the summit to the flank. You can read more about it __[here](https://www.usgs.gov/news/k-lauea-volcano-erupts)__. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will use the functions in \"makeTS.py\" to create a velocity map using the ARIA interferograms that I've downloaded. I've converted them to an aligned stack in the directory jlmd9g/interferogram_stack "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls jlmd9g/unwrappedPhase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# makeTS is a module containing several functions, including dt2fracYear. We'll import them all!\n",
    "!cp jlmd9g/makeTS.py .\n",
    "from makeTS import *  # NOTE: generally this syntax is not a good idea, but for this small package it's ok\n",
    "ifgList = glob.glob('jlmd9g/unwrappedPhase/*.vrt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the list of interferograms\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we will get the list of dates\n",
    "datePairs, dates = getDates(ifgList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the date pairs and dates\n",
    "# what is the difference? Which one relates to interferograms and which relates to time-series? \n",
    "# Your answers here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, use the dt2fracYear function to convert python datetimes to fractional dates\n",
    "fracDates = np.array([dt2fracYear(d) for d in dates])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interferograms to time-series\n",
    "To estimate the displacement at each date, we use a G-matrix. This means that we will solve a linear system: \n",
    "**I = Gd**, where **I** is the stack of interferograms (actually, there is one stack for each pixel in each interferogram), **G** is called the \"G-matrix\" (or model matrix), and **d** is the displacement between each acquisition time and the one before. \n",
    "\n",
    "The columns of the **G**-matrix correspond to each acqiusition date, and the rows correspond to each interferogram. The elements of this matrix are simple: each interferogram gets a row, with a \"-1\" at the location of the second acquisition date, and a \"+1\" at the first acquisition date. Something like this:  \n",
    "row 1: [0 0 0 0 -1 1 0 0]  \n",
    "row 2: [0 0 0 0 0 0 -1 1]  \n",
    "row 3: [-1 0 1 0 0 0 0 0]  \n",
    "row 4: [-1 0 0 1 0 0 0 0]  \n",
    "would represent a potential G-matrix. In this case, we have fewer interferograms then dates, but in most cases there will be more. We have to have, at a minimum, one interferogram using every acquisition date. \n",
    "\n",
    "For those of you familiar with linear algebra and inverse theory, this G-matrix is inverted to solve for the displacements at each time period. Since we have more interferograms than acquisition times, this is an _over-determined_ system, and we will solve for the best-fitting time-series that matches all of the interferograms. We could then go back to the interfergrams by differencing the displacements between the two corresponding acquisition times. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G itself is not related to the data; it only depends on the model (in this case, which dates are linked by which interferograms)\n",
    "G = makeG(dates, datePairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the details about the size of the interferogram raster images: size, projection, and so forth\n",
    "xSize, ySize, dType, geoProj, trans, noDataVal, Nbands = readRaster(ifgList[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read all the interferograms into memory\n",
    "data = getData(ifgList,1)\n",
    "print(data.shape) # this should be a big 3-d matrix with each interferogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference region\n",
    "**InSAR is a relative measurement.** This is because the measurements are modulo $2\\pi$, so we never know what the absolute displacements are without comparing to some other measurement, such as GPS. In order to create a time-series, we have to relate all the interferograms, so we have to create a \"reference point\" (or reference region) where all the interferograms are identical. The only way to do this is to subtract out the value of the reference point from each unwrapped interferogram **before** estimating the time-series. This is what \"dereference\" does in the code below. Passing \"None\" to refCenter will use the center of the image, but you can adjust this to fit your preferences if needed. The refCenter pixel will have zero displacement in the time-series, so you want to pick an area that is not deforming. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dereference(data, taxis=0,refCenter=None,refSize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the interferograms referenced to a common region, and the G-matrix for relating dates and interferograms, we can now solve for displacements through time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go from interferograms to time-series\n",
    "tsArray = makeTS(G, data, fracDates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: \n",
    "The native InSAR displacements are in radians. To convert to meters, we need to multiply the displacements by $\\frac{\\lambda}{-4\\pi}$, where $\\lambda$ is the radar wavelength (=0.056 meters, or 5.6 cm, for Sentinel 1). This assumes \"date_2 - date_1\". When we do \"date_1 - date_2\", then we don't use the negative sign: $\\frac{\\lambda}{4\\pi}$. ARIA products use the \"date_2 - date_1\" convention. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data is still in phase (radians) so we'll convert to meters\n",
    "tsArray = convertRad2meters(tsArray, lam=0.056) # wavelength lam is 5.6 cm for Sentinel-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot below will compare a pixel located on the volcano to one on the summit of the mountain caldera. During the eruption, the volcano inflated and erupted while the summit actually deflated due to magma moving out the side. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot single pixels through time\n",
    "plt.plot(fracDates, tsArray[:,1100,1300])  # this is a pixel on the Kilauea volcano\n",
    "plt.plot(fracDates, tsArray[:,700,1000])  # this is a pixel on the summit of Moana Loa\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Displacement (m)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Velocity estimation\n",
    "We can use the time-series to estimate various parameters of the event, such as the total or average rate of displacement. These can then be used to infer properties of the eruption, such as the volume of erupted fluid. We will estimate the mean line-of-sight velocity below. **Remember** that the line-of-sight for a satellite is mainly sensitive to vertical motion, so most of the displacements are vertical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note:\n",
    "InSAR displacements change sign depending on the order you create the interferograms. Each interferogram has two images that are differenced, so you can do \"date_1 - date_2\" _or_ \"date_2 - date_1\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the mean velocity by fitting a line\n",
    "vel = findMeanVel(tsArray, fracDates, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can plot the mean velocity throughout the period\n",
    "cax = plt.imshow(vel, vmax=None,vmin=None) # vmax and vmin adjusts the minimum and maximum color shown\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data to an HDF5 file for use later\n",
    "filename='ts.h5' # create your own filename with the path to your writeable folder, for example, 'jlmd9g/ts.h5'\n",
    "writeTS2HDF5(tsArray, fracDates,vel,filename='ts.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When turning in your notebook, make sure to use \"plt.show()\" in each cell with a plot so that it will show for me when I open your turned-in version. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "GettingStartedWithARIAtools.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
